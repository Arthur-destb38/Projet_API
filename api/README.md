# Crypto Sentiment API ğŸª™

API d'analyse de sentiment pour cryptomonnaies via webscraping Reddit et FinBERT.

**Master 2 MoSEF Data Science 2024-2025**  
Cours: Webscraping & API - JosÃ© Ãngel GarcÃ­a SÃ¡nchez

---

## ğŸ¯ Objectif

Adaptation de la mÃ©thodologie de l'article "From Tweets to Returns: Validating LLM-Based Sentiment Signals in Energy Stocks" au marchÃ© des cryptomonnaies:

- **Source originale**: Twitter â†’ **Adaptation**: Reddit (API gratuite)
- **MarchÃ© original**: Actions Ã©nergÃ©tiques â†’ **Adaptation**: Cryptomonnaies (BTC, ETH, SOL)
- **ModÃ¨le NLP**: FinBERT (sentiment financier)

---

## ğŸš€ Installation

```bash
# Cloner le projet
cd crypto_sentiment_api

# Installer Poetry (si nÃ©cessaire)
pip install poetry

# Installer les dÃ©pendances
poetry install

# Lancer l'API
poetry run uvicorn app.main:app --reload
```

L'API sera disponible sur `http://localhost:8000`

**Note:** Chrome doit Ãªtre installÃ© pour le webscraping Selenium.

---

## ğŸ”Œ Endpoints

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/` | Page d'accueil HTML |
| GET | `/health` | Health check |
| POST | `/scrape` | Webscraping Reddit |
| POST | `/sentiment` | Analyse FinBERT |
| GET | `/prices/{crypto}` | Prix CoinGecko |
| POST | `/analyze` | Pipeline complet |
| POST | `/econometrics` | Analyse VAR & Granger |

---

## ğŸ“Š Exemples d'utilisation

### Scraper Reddit
```bash
curl -X POST "http://localhost:8000/scrape" \
  -H "Content-Type: application/json" \
  -d '{"subreddit": "Bitcoin", "crypto": "BTC", "limit": 10}'
```

### Analyser le sentiment
```bash
curl -X POST "http://localhost:8000/sentiment" \
  -H "Content-Type: application/json" \
  -d '{"texts": ["Bitcoin is pumping!", "Market is crashing"]}'
```

### Prix d'une crypto
```bash
curl "http://localhost:8000/prices/bitcoin"
```

### Pipeline complet
```bash
curl -X POST "http://localhost:8000/analyze" \
  -H "Content-Type: application/json" \
  -d '{"crypto": "bitcoin", "subreddit": "Bitcoin", "limit": 50}'
```

### Analyse Ã©conomÃ©trique (VAR, Granger)
```bash
curl -X POST "http://localhost:8000/econometrics" \
  -H "Content-Type: application/json" \
  -d '{"crypto": "bitcoin", "subreddit": "Bitcoin", "limit": 100, "days": 30, "maxlag": 14}'
```

La rÃ©ponse inclut:
- Tests de stationnaritÃ© (ADF)
- ModÃ¨le VAR avec lag optimal
- Tests de causalitÃ© de Granger bidirectionnels
- CorrÃ©lations croisÃ©es avec lag optimal
- Conclusion sur la relation sentiment â†’ returns

---

## ğŸ› ï¸ Stack Technique

- **FastAPI**: Framework API async
- **Selenium**: Webscraping avec simulation comportement humain
- **BeautifulSoup**: Parsing HTML
- **FinBERT**: ModÃ¨le de sentiment financier (HuggingFace)
- **CoinGecko**: API prix crypto (gratuite)
- **Statsmodels**: VAR, tests de Granger, ADF
- **Pandas/NumPy**: Data manipulation
- **Pydantic**: Validation des donnÃ©es
- **Uvicorn**: Serveur ASGI

---

## ğŸ“ Structure du Projet

```
crypto_sentiment_api/
â”œâ”€â”€ pyproject.toml      # DÃ©pendances Poetry
â”œâ”€â”€ README.md
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py         # Endpoints FastAPI
â”‚   â”œâ”€â”€ scraper.py      # Reddit scraper (PRAW)
â”‚   â”œâ”€â”€ sentiment.py    # FinBERT analyzer
â”‚   â”œâ”€â”€ prices.py       # CoinGecko client
â”‚   â”œâ”€â”€ utils.py        # Text cleaning
â”‚   â””â”€â”€ econometrics.py # VAR, Granger causality
â””â”€â”€ templates/
    â””â”€â”€ index.html      # Page d'accueil
```

---

## ğŸ“‹ Status Codes HTTP

- `200 OK`: RequÃªte rÃ©ussie
- `201 Created`: Nouvelle ressource crÃ©Ã©e (scraping)
- `400 Bad Request`: ParamÃ¨tres invalides
- `404 Not Found`: Ressource non trouvÃ©e
- `500 Internal Server Error`: Erreur serveur

---

## ğŸ”— PrÃ©requis Selenium

1. Installer Chrome ou Chromium
2. ChromeDriver sera gÃ©rÃ© automatiquement par `webdriver-manager`

Le scraper utilise `old.reddit.com` (plus facile Ã  parser) et simule un comportement humain:
- Random delays entre actions
- User-Agent rotation
- Scrolling naturel
- Anti-detection flags

---

## ğŸ“š Documentation

- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`
- OpenAPI: `http://localhost:8000/openapi.json`
